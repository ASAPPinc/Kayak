<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print" />
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <title>Kayak: Easy Deep Learning in Python</title>
  </head>

  <body>
    <div id="container">
      <div class="inner">

        <header>
          <h1>Kayak: Easy Deep Learning in Python</h1>
          <h2>Kayak is a library that makes it easy to explore
          different architectures for deep neural networks and apply
          them to data.</h2>
          <h2>Maintained by
          the <a href="http://hips.seas.harvard.edu">Harvard
          Intelligent Probabilistic Systems (HIPS) group</a>. Check out more HIPS code
          at <a href="http://hips.github.io">hips.github.io</a>.</h2>
        </header>

        <section id="downloads" class="clearfix">
          <a href="https://github.com/HIPS/Kayak/zipball/master" id="download-zip" class="button"><span>Download .zip</span></a>
          <a href="https://github.com/HIPS/Kayak/tarball/master" id="download-tar-gz" class="button"><span>Download .tar.gz</span></a>
          <a href="https://github.com/HIPS/Kayak" id="view-on-github" class="button"><span>View on GitHub</span></a>
        </section>

        <hr>

        <section id="main_content">
          <h3>Easy Specification of Neural Network Architectures</h3>
          <p>
          Neural networks are a powerful way to perform function
          approximation.  They are a way to perform adaptive basis
          function regression or classification, and have proven
          themselves over the years to be highly effective at many
          supervised learning tasks such as visual object recognition
          and speech processing.  The backpropagation algorithm --
          simply the application of the chain rule for reverse-mode
          automatic differentiation -- makes it straightforward to
          find the gradient of a training loss function in terms of
          parameters, and then apply optimization procedures such as
          stochastic gradient descent.
          </p>
          <p>
          It is an active area of research, however, to determine what
          the right neural network architecture should be for any
          given data set. It's annoying to have to derive new
          gradients and write new code, however.  Kayak makes this
          easy and automatic.  Other tools do this as well,
          notably <a href="https://github.com/Theano/Theano">Theano</a>
          and <a href="http://torch.ch/">Torch</a>.  Kayak is almost
          certainly slower and less featureful than these tools; it is
          intended to be an easy-to-use alternative with low overhead,
          using Python tools with which you are already familiar.
          </p>
          <p>
          The point of Kayak is to be highly modular and allow you to
          build neural network architectures, broadly defined, by
          composing together simple pieces that implement both
          ``classic'' layer mechanics such as matrix multiplication
          and sigmoidal nonlinearities, as well as newer ideas like
          dropout and rectified linear units.  The point is to wind up
          with Python code that looks pretty familiar:
<pre><code># Super easy logistic regression.
inputs  = Inputs(train_inputs)                    # Specify training input features
targets = Targets(train_targets)                  # Specify training target outputs
weights = Parameter(randn(768, 10))               # Create weight parameters
output  = LogSoftMax(MatMult(inputs, weights))    # Linear layer with softmax nonlinearity
loss    = MatSum(LogMultinomial(output, targets)) # Negative multinomial loss function
grad_W  = loss.grad(weights)                      # Find the gradient of the training loss in terms of the weights
</code></pre>
          </p>

<h3>Automatic Differentiation</h3>
          <p>
          Nobody likes taking derivatives over and over again to
          figure out what the gradient of the loss function should be.
          This can make it slow and annoying to figure out what a good
          architecture should be, plus it is prone to errors.  Kayak's
          main purpose is to make this very, very easy.  You specify a
          directed acyclic graph (DAG) of computation, as in the
          logistic regression example above, and you can find the
          gradient of a scalar output simply by calling the grad()
          method, where the argument is whatever gradient you care
          about.  It's that easy.  If you want to add a new module to
          Kayak, you just subclass the Differentiable class and
          implement local value and gradient computations.
          </p>

<h3>Feature Roadmap</h3>
<ul>
  <li>Optional Nvidia GPU integration via <a href="https://github.com/cudamat/cudamat">CUDAmat</a>.</li>
  <li>Optional Xeon Phi integration via <a href="https://github.com/orippel/micmat">MICmat</a>.</li>
  <li>Convolution and spatial pooling for computer vision problems.</li>
  <li>Integration with <a href="https://github.com/JasperSnoek/spearmint">Bayesian optimization</a> for hyperparameter tuning.</li>
  <li>Implementation of Hessian-vector products via <a href="http://www.bcl.hamilton.ie/~barak/papers/nc-hessian.pdf">Perlmutter's R-propagation</a>.</li>
</ul>

<footer>
  Kayak: Easy Deep Learning in Python is maintained by
  the <a href="http://hips.seas.harvard.edu">Harvard Intelligent
  Probabilistic Systems</a> group.  More software is available
  on <a href="https://github.com/HIPS">the HIPS Github page</a>.<br>
  This page was generated by <a href="http://pages.github.com">GitHub
  Pages</a>. Tactile theme
  by <a href="https://twitter.com/jasonlong">Jason Long</a>.
</footer>

        
      </div>
    </div>
  </body>
</html>
